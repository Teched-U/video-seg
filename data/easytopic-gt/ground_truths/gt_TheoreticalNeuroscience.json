{"0": "Theoretical Neuroscience and  Deep Learning Theory", "20": "Theoretical neuroscience in the disciplinary landscape", "117": "Neural circuits and behavior: theory, computation and experiment", "143": "Motivations for an alliance between theoretical neuroscience and  theoretical machine learning", "339": "Talk Outline", "423": "The shape of things to come\u2026 on monkeys and models - 1", "706": "The shape of things to come\u2026 on monkeys and models - 2", "835": "Deep neural network models of the retinal response to natural scenes", "858": "A brief tour of the retina", "895": "Linear-Nonlinear models", "905": "How well do linear-nonlinear models explain the retina in natural vision?", "931": "Modeling ganglion cells with convolutional neural networks (CNNs) - 1", "947": "Modeling ganglion cells with convolutional neural networks (CNNs) - 2", "961": "Modeling ganglion cells with convolutional neural networks (CNNs) - 3", "973": "Modeling ganglion cells with convolutional neural networks (CNNs) - 4", "980": "Modeling ganglion cells with convolutional neural networks (CNNs) - 5", "1015": "Convolutional neural network model", "1023": "CNNs approach retinal reliability", "1056": "CNNs trained on less data outperform simpler models on more data", "1072": "Features bear striking resemblance to internal structure in retina", "1131": "Most retinal neurons have sub-Poisson variability (while LNP models are Poisson)", "1139": "We can inject Gaussian noise into each hidden unit of our CNN model", "1141": "Model has lower variance than data", "1142": "However model uncertainty has same scaling relationship as the retina", "1145": "Capturing contrast adaptation from retinal responses to natural scenes", "1183": "Summary", "1200": "Talk Outline", "1216": "Some of the theoretical puzzles of deep learning", "1282": "A Mathematical Theory of  Semantic Development* ", "1301": "What is \u201csemantic cognition\u201d? ", "1353": "Psychophysical tasks that probe semantic cognition", "1376": "The project that really keeps me up at night", "1457": "Semantic Cognition Phenomena", "1470": "A Network for Semantic Cognition", "1496": "Evolution of internal representations", "1503": "A Network for Semantic Cognition", "1511": "Evolution of internal representations", "1570": "Categorical representations in human and monkey", "1635": "Categorical representations in human and monkey", "1640": "Evolution of internal representations", "1647": "Theoretical questions ", "1666": "Problem formulation", "1705": "Nontrivial learning dynamics", "1755": "Learning dynamics - 1", "1763": "Problem formulation", "1787": "Learning dynamics - 2", "1794": "Learning dynamics - 3", "1837": "Decomposing input-output correla6ons", "1870": "Analytical  learning trajectory", "1951": "Origin of the rapid learning transi6on:   saddle point dynamics in synaptic weight space", "2009": "Take home messages, so far", "2042": "Learning hierarchical structure", "2093": "Connecting hierarchical generative  models and neural network learning", "2132": "A hierarchical branching diffusion process", "2140": "Object analyzer vectors", "2228": "Singular values ", "2233": "Progressive differentiation - 1", "2245": "Progressive differentiation - 2", "2255": "Progressive differentiation - 3", "2286": "Connecting hierarchical generative  models and neural network learning", "2465": "Other work", "2543": "What is a category and what makes it \u201ccoherent?\u201d - 1", "2673": "What is a category and what makes it \u201ccoherent?\u201d - 2", "2706": "What is a category and what makes it \u201ccoherent?\u201d - 3", "2747": "What is a category and what makes it \u201ccoherent?\u201d - 4", "2750": "What is a category and what makes it \u201ccoherent?\u201d - 5", "2785": "What is a category and what makes it \u201ccoherent?\u201d - 6", "2795": "What is a category and what makes it \u201ccoherent?\u201d - 7", "3051": "What is a category and what makes it \u201ccoherent?\u201d - 8", "3053": "Towards a theory of deep learning dynamics", "3060": "Dynamic Isometry Initialization ", "3073": "Some of the theoretical puzzles of deep learning", "3100": "High dimensional nonconvex optimization", "3155": "General properties of error landscapes in high dimensions", "3370": "Properties of Error Landscapes on the Synaptic Weight Space of a Deep Neural Net", "3469": "How to descend saddle points", "3550": "Performance of saddle free Newton in learning deep neural networks", "3738": "How to descend saddle points", "3757": "Some of the theoretical puzzles of deep learning", "3826": "A theory of deep neural expressivity  through transient chaos", "3846": "Seminal works on the expressive power of depth - 1", "3903": "Seminal works on the expressive power of depth - 2", "3970": "Seminal works on the expressive power of depth - 3", "4007": "Questions", "4050": "Limitations of prior work", "4109": "Another perspective on the advantage of depth: disentangling", "4116": "A maximum entropy ensemble of deep random networks ", "4150": "Emergent, deterministic signal propagation  in random neural networks ", "4268": "Propagation of two points through a deep network - 1", "4364": "Propagation of a manifold through a deep network - 2", "4382": "Propagation of a manifold through a deep network - 3", "4472": "Propagation of a manifold through a deep network  -4", "4508": "Riemannian geometry I: Euclidean length", "4519": "Riemannian geometry II: Extrinsic Gaussian Curvature", "4526": "Curvature propagation: theory and experiment ", "4530": "Exponential expressivity is not achievable by shallow nets", "4595": "Boundary disentangling: theory - 1", "4602": "Boundary disentangling: theory - 2", "4606": "Boundary disentangling: experiment ", "4608": "Summary ", "4617": "Some of the theoretical puzzles of deep learning", "4629": "Statistical mechanics of high dimensional data analysis ", "4720": "Optimal inference in high dimensions - 1", "4863": "Optimal inference in high dimensions - 2", "4877": "Optimal inference in high dimensions - 3", "4901": "Optimal inference in high dimensions - 4", "5023": "More generally: upper bounds on generalization error", "5205": "Recent observations on generalization in deep nets", "5235": "More generally: upper bounds on generalization error", "5276": "Recent observations on generalization in deep nets", "5378": "Talk Outline", "5388": "There are more things in heaven and earth\u2026 - 1", "5457": "There are more things in heaven and earth\u2026 - 2", "5487": "There are more things in heaven and earth - 3", "5525": "Continual learning through synaptic intelligence - 1", "5529": "Continual learning through synaptic intelligence - 2", "5539": "Summary", "5544": "References"}