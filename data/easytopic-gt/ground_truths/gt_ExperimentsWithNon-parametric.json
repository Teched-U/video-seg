{"0": "Non-parametric Methods for Unsupervised Semantic Modelling", "67": "Outline - 1", "121": "Information Overload", "127": "Information Warfare", "141": "Outline - 2", "158": "Probability Vectors", "198": "Sharing/Inheritance with a Probability Hierarchy", "309": "Overview: Latent Semantic Modelling", "444": "Outline - 3", "446": "Dirichlet distributions", "453": "4-D Dirichlet samples", "541": "The Dirichlet Distribution", "542": "Dirichlet Details", "543": "Outline - 4", "562": "Latent Dirichlet Allocation", "644": "Learning Algorithms with Dirichlets", "659": "Context Free Grammar", "666": "Learning Algorithms with Dirichlets", "675": "Context Free Grammar", "712": "Probabilistic Context Free Grammar, cont.", "744": "Context Free Grammar", "755": "Probabilistic Context Free Grammar, cont.", "764": "Bayesian Networks", "768": "Bayesian Model Averaging (BMA) for Bayesian Networks", "769": "Bayesian Model Averaging (BMA) for Bayesian Networks, cont.", "770": "N-grams", "817": "Decision Trees", "818": "Breiman\u2019s Random Forests or Bagging of Decision Trees", "819": "Bayesian Model Averaging and Non-parametrics Storyline", "843": "Bayesian Model Averaging and Non-parametrics Storyline, cont.", "915": "Motivation", "916": "Outline - 5", "920": "Dirichlet Process", "923": "Bayesian Idea: Similar Context Means Similar Word", "1026": "Bayesian N-grams", "1030": "Bayesian N-grams, cont.", "1048": "Historical Context - 1", "1089": "Historical Context - 2", "1134": "Outline - 6", "1137": "Historical Context - 2", "1178": "Why We Prefer DPs and PYPs over Dirichlets!", "1189": "The Ideal Hierarchical Component?", "1239": "Why We Prefer DPs and PYPs over Dirichlets!", "1294": "Outline - 7", "1298": "Component Models, Generally", "1336": "Matrix Approximation View", "1388": "Why Topic Models?", "1423": "Topic Models: Potential for Semantics", "1461": "Topic Models: Just an Intermediate Goal", "1515": "ASIDE: Aspects, Ratings and Sentiments", "1543": "Evaluation - 1", "1600": "Evaluation - 2", "1650": "Topic Models: Potential for Semantics", "1676": "Evaluation - 2", "1697": "Outline - 8", "1699": "Previous Work", "1746": "Text and Burstiness", "1860": "Aside: Burstiness and Information Retrieval", "1927": "Outline - 9", "1938": "Evolution of Models - 1", "2030": "Evolution of Models - 2", "2062": "Previous Work", "2087": "Evolution of Models - 3", "2100": "Evolution of Models - 4", "2125": "Evolution of Models - 5", "2248": "Our Non-parametric Topic Model - 1", "2249": "Our Non-parametric Topic Model - 2", "2261": "Our Non-parametric Topic Model - 3", "2274": "Our Non-parametric Topic Model - 4", "2302": "Design Notes - 1", "2303": "Design Notes - 2", "2304": "Design Notes - 3", "2305": "Performance on Reuters-21578 ModLewis Split", "2393": "Perplexity performance on MLT Data for different Topics", "2394": "Comparison to PCVB0 and Mallet", "2462": "Comparison to Bryant+Sudderth (2012) on NIPS data", "2500": "Comparison to FTM and LIDA", "2502": "Conclusion on Topic Models - 1", "2506": "Conclusion on Topic Models - 4", "2585": "Conclusion on Topic Models - 5", "2659": "Outline - 11", "2664": "Aspect-based Opinion Aggregation", "2682": "Explaining the Model - 1", "2712": "Explaining the Model - 2", "2713": "Explaining the Model - 3", "2714": "Explaining the Model - 4", "2735": "Explaining the Model - 1", "2753": "Explaining the Model - 4", "2817": "Outline - 12", "2835": "Task, Roughly - 1", "2900": "Segmentation Model\u2013Generative process", "2905": "Experiments on two meeting transcripts", "2969": "Conclusion of Segmentation with a Structured Topic Model - 1", "2970": "Conclusion of Segmentation with a Structured Topic Model - 2", "2971": "Fun with Bibliographies (Lim etal ACML 2014)", "3026": "Fun with Aspects and Sentiment (Lim etal CIKM 2014)", "3028": "Conclusion"}