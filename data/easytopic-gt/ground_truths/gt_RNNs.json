{"0": "Recurrent Neural Networks", "2": "Recurrent Neural Networks - 1", "196": "Recurrent Neural Networks - 2", "234": "Generative RNNs", "611": "Recurrent Neural Networks - 2", "715": "Generative RNNs", "749": "Conditional Distributions", "925": "Maximum Likelihood = Teacher Forcing", "1095": "Ideas to reduce the train/generate mismatch in teacher forcing", "1294": "Increasing the Expressive Power of RNNs with more Depth", "1401": "Bidirectional RNNs, Recursive Nets, Multidimensional RNNs, etc.", "1562": "Multiplicative Interactions", "1598": "Bidirectional RNNs, Recursive Nets, Multidimensional RNNs, etc.", "1599": "Increasing the Expressive Power of RNNs with more Depth", "1648": "Learning Long-Term Dependencies with Gradient Descent is Difficult", "1674": "Simple Experiments from 1991 while I was at MIT", "1730": "How to store 1 bit?", "1846": "Robustly storing 1 bit in the presence of bounded noise", "1945": "Storing Reliably - Vanishing gradients", "2042": "Vanishing or Exploding Gradients", "2087": "Why it hurts gradient-based learning", "2299": "Vanishing Gradients in Deep Nets are Different from the Case in RNNs", "2390": "To store information robustly the dynamics must be contractive", "2444": "RNN Tricks", "2450": "Dealing with Gradient Explosion by Gradient Norm Clipping", "2521": "How to store 1 bit?", "2561": "Dealing with Gradient Explosion by Gradient Norm Clipping", "2652": "Conference version (1993) of the 1994 paper by the same authors", "2668": "Delays & Hierarchies to Reach Farther", "2810": "Fighting the vanishing gradient: LSTM & GRU", "2833": "Delays & Hierarchies to Reach Farther", "2851": "Fighting the vanishing gradient: LSTM & GRU", "2948": "Fast Forward 20 years: Attention Mechanisms for Memory Access", "2953": "Fighting the vanishing gradient: LSTM & GRU", "3127": "Fast Forward 20 years: Attention Mechanisms for Memory Access", "3272": "Large Memory Networks: Sparse Access Memory for Long-Term Dependencies", "3400": "Attention Mechanism for Deep Learning", "3619": "End-to-End Machine Translation with Recurrent Nets and Attention Mechanism", "3629": "Google-Scale NMT Success", "3754": "Pointing the Unknown Words", "3879": "Designing the RNN Architecture", "3960": "It makes a difference", "3985": "Designing the RNN Architecture", "4002": "Near-Orthogonality to Help Information Propagation", "4040": "Variational Generative RNNs", "4082": "Variational Hierarchical RNNs for Dialogue Generation", "4102": "VHRNN Results \u2013 Twitter Dialogues", "4103": "Other Fully-Observed Neural Directed Graphical Models", "4105": "Neural Auto-Regressive Models", "4297": "NADE: Neural AutoRegressive Density Estimator", "4339": "Pixel RNNs", "4373": "Forward Computation of the Gradient", "5090": "Delays & Hierarchies to Reach Farther"}